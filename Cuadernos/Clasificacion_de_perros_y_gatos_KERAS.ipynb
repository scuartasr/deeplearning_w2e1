{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MO7qw82lO4fu"
   },
   "source": [
    "# Clasificación de perros y gatos con Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5DRthraO9mn"
   },
   "source": [
    "Step 1: Conexión con Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAMV9UKVOarT",
    "outputId": "19b66088-ef67-485b-fd26-d8b874beeb1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "base_dir is:  /content/drive/My Drive/Classroom/Topicos_Avanzados_IA/dataset_dogs_vs_cats/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "root_dir = \"/content/drive/My Drive/\"\n",
    "base_dir = root_dir + 'Classroom/Topicos_Avanzados_IA/dataset_dogs_vs_cats/'\n",
    "print(\"base_dir is: \", base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7yCE5IxnMW_",
    "outputId": "f72c1fbd-7510-4cd6-dfed-90922fa81a7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  train\n"
     ]
    }
   ],
   "source": [
    "!ls \"/content/drive/My Drive/Classroom/Topicos_Avanzados_IA/dataset_dogs_vs_cats/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TU1oNLBpDt3"
   },
   "source": [
    "Step 2: Preprocessing and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ymgfIsjPVTKa",
    "outputId": "2d58cdfb-b6ae-4e23-90b5-99c28546c905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 1999 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an ImageDataGenerator for rescaling images\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Load training data\n",
    "train = datagen.flow_from_directory(\n",
    "    directory='/content/drive/My Drive/Classroom/Topicos_Avanzados_IA/dataset_dogs_vs_cats/train',\n",
    "    target_size=(150, 150),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "# Load test data\n",
    "test = datagen.flow_from_directory(\n",
    "    directory='/content/drive/My Drive/Classroom/Topicos_Avanzados_IA/dataset_dogs_vs_cats/test',\n",
    "    target_size=(150, 150),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZZqhhl2pVt-"
   },
   "source": [
    "Step 3: Build the CNN Model\n",
    "\n",
    "Includes convolutional layers, max-pooling, and fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KOx6qNjkpNsP",
    "outputId": "a295f666-d170-4f3f-a70a-b338d4bfdb55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dropout, MaxPooling2D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Initialize the model\n",
    "classifier = Sequential()\n",
    "\n",
    "# Convolution layer 1\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3), activation='relu', padding='same'))\n",
    "classifier.add(MaxPooling2D(strides=(2,2), pool_size=(2, 2)))\n",
    "\n",
    "# Convolution layer 2\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(strides=(2,2), pool_size=(2, 2)))\n",
    "\n",
    "# Convolution layer 3\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(strides=(2,2), pool_size=(2, 2)))\n",
    "\n",
    "# Convolution layer 4\n",
    "classifier.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(strides=(2,2), pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the results from convolutional layers\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "classifier.add(Dense(units=600, activation='relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "classifier.compile(optimizer=Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3nOtNQopu3N"
   },
   "source": [
    "Step 4: Train the Model and graph the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 880
    },
    "id": "gBF4CBW3FWMY",
    "outputId": "54866ad7-4f0c-4a8e-c841-3e91bdcc6f67",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train the model and capture the history\n",
    "history = classifier.fit(\n",
    "    train,\n",
    "    steps_per_epoch=train.samples // train.batch_size,\n",
    "    epochs=5,\n",
    "    validation_data=test,\n",
    "    validation_steps=test.samples // test.batch_size\n",
    ")\n",
    "\n",
    "# Plotting training & validation accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGryzOSLp7LP"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-O25yfNWo_t",
    "outputId": "e6f75576-3c4f-4a6c-ff8a-5145f5df27ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "251/251 [==============================] - 2718s 11s/step - loss: 0.6419 - accuracy: 0.6107 - val_loss: 0.5777 - val_accuracy: 0.6965\n",
      "Epoch 2/25\n",
      "251/251 [==============================] - 42s 167ms/step - loss: 0.5383 - accuracy: 0.7290 - val_loss: 0.5164 - val_accuracy: 0.7509\n",
      "Epoch 3/25\n",
      "251/251 [==============================] - 42s 166ms/step - loss: 0.4860 - accuracy: 0.7660 - val_loss: 0.5023 - val_accuracy: 0.7573\n",
      "Epoch 4/25\n",
      "251/251 [==============================] - 41s 165ms/step - loss: 0.4387 - accuracy: 0.7975 - val_loss: 0.4707 - val_accuracy: 0.7830\n",
      "Epoch 5/25\n",
      "251/251 [==============================] - 41s 165ms/step - loss: 0.3964 - accuracy: 0.8202 - val_loss: 0.4074 - val_accuracy: 0.8161\n",
      "Epoch 6/25\n",
      "251/251 [==============================] - 41s 164ms/step - loss: 0.3605 - accuracy: 0.8412 - val_loss: 0.3914 - val_accuracy: 0.8260\n",
      "Epoch 7/25\n",
      "251/251 [==============================] - 41s 164ms/step - loss: 0.3051 - accuracy: 0.8700 - val_loss: 0.3562 - val_accuracy: 0.8393\n",
      "Epoch 8/25\n",
      "251/251 [==============================] - 40s 159ms/step - loss: 0.2605 - accuracy: 0.8911 - val_loss: 0.3521 - val_accuracy: 0.8478\n",
      "Epoch 9/25\n",
      "251/251 [==============================] - 40s 161ms/step - loss: 0.2220 - accuracy: 0.9099 - val_loss: 0.3687 - val_accuracy: 0.8438\n",
      "Epoch 10/25\n",
      "251/251 [==============================] - 40s 158ms/step - loss: 0.1825 - accuracy: 0.9282 - val_loss: 0.3975 - val_accuracy: 0.8413\n",
      "Epoch 11/25\n",
      "251/251 [==============================] - 40s 158ms/step - loss: 0.1394 - accuracy: 0.9447 - val_loss: 0.3742 - val_accuracy: 0.8542\n",
      "Epoch 12/25\n",
      "251/251 [==============================] - 40s 159ms/step - loss: 0.1166 - accuracy: 0.9564 - val_loss: 0.4011 - val_accuracy: 0.8468\n",
      "Epoch 13/25\n",
      "251/251 [==============================] - 40s 158ms/step - loss: 0.0821 - accuracy: 0.9713 - val_loss: 0.4495 - val_accuracy: 0.8374\n",
      "Epoch 14/25\n",
      "251/251 [==============================] - 41s 163ms/step - loss: 0.0643 - accuracy: 0.9783 - val_loss: 0.4644 - val_accuracy: 0.8507\n",
      "Epoch 15/25\n",
      "251/251 [==============================] - 40s 158ms/step - loss: 0.0509 - accuracy: 0.9821 - val_loss: 0.5304 - val_accuracy: 0.8492\n",
      "Epoch 16/25\n",
      "251/251 [==============================] - 40s 160ms/step - loss: 0.0326 - accuracy: 0.9913 - val_loss: 0.5560 - val_accuracy: 0.8596\n",
      "Epoch 17/25\n",
      "251/251 [==============================] - 39s 157ms/step - loss: 0.0265 - accuracy: 0.9923 - val_loss: 0.5777 - val_accuracy: 0.8492\n",
      "Epoch 18/25\n",
      "251/251 [==============================] - 40s 158ms/step - loss: 0.0330 - accuracy: 0.9899 - val_loss: 0.6401 - val_accuracy: 0.8344\n",
      "Epoch 19/25\n",
      "251/251 [==============================] - 39s 157ms/step - loss: 0.0219 - accuracy: 0.9938 - val_loss: 0.6045 - val_accuracy: 0.8482\n",
      "Epoch 20/25\n",
      "251/251 [==============================] - 39s 157ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.6252 - val_accuracy: 0.8591\n",
      "Epoch 21/25\n",
      "251/251 [==============================] - 39s 157ms/step - loss: 0.0417 - accuracy: 0.9853 - val_loss: 0.5559 - val_accuracy: 0.8517\n",
      "Epoch 22/25\n",
      "251/251 [==============================] - 39s 156ms/step - loss: 0.0250 - accuracy: 0.9914 - val_loss: 0.7205 - val_accuracy: 0.8438\n",
      "Epoch 23/25\n",
      "251/251 [==============================] - 39s 157ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.6870 - val_accuracy: 0.8576\n",
      "Epoch 24/25\n",
      "251/251 [==============================] - 39s 155ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.7444 - val_accuracy: 0.8576\n",
      "Epoch 25/25\n",
      "251/251 [==============================] - 40s 159ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.7554 - val_accuracy: 0.8566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5baef6fb38>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo de clasificacion CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "## convolucion #1\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (150, 150, 3), activation = 'relu', padding='same'))\n",
    "classifier.add(MaxPooling2D(strides=(2,2), pool_size = (2, 2)))\n",
    "\n",
    "## convolucion #2\n",
    "classifier.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(strides=(2,2), pool_size = (2, 2)))\n",
    "\n",
    "## convolucion #3\n",
    "\n",
    "classifier.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(strides=(2,2), pool_size = (2, 2)))\n",
    "\n",
    "## convolucion #4\n",
    "\n",
    "classifier.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(strides=(2,2), pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "classifier.add(Flatten())  ### Aplanamos los valores\n",
    "\n",
    "classifier.add(Dense(units = 600, activation = 'relu'))  ## utilizamos 600 neuronas\n",
    "\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid')) ## capa final sigmoid con una sola neurona\n",
    "\n",
    "sgd = SGD(lr=0.1)\n",
    "classifier.compile(optimizer = Adam(lr=0.0003), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.fit(train,\n",
    "#steps_per_epoch = 8000,\n",
    "epochs = 25,\n",
    "validation_data = test,\n",
    "shuffle = True\n",
    "#validation_steps = 2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCtYZOy7FZdo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff01EW2gsfdC"
   },
   "source": [
    "## Transfer learning\n",
    "Three models — VGG16, EfficientNet, and ResNet50 — are solid choices, they have different strengths. Here's a comparison:\n",
    "\n",
    "- VGG16: #Alternative VGG19\n",
    "\n",
    "Pros: Simple and easy to use. Good baseline for smaller datasets.\n",
    "Cons: Large number of parameters, which can lead to slower training and high memory usage. It is less efficient than newer models like EfficientNet or ResNet.\n",
    "Best for: Simpler problems or when you need a straightforward approach.\n",
    "\n",
    "- EfficientNet:  # Alternative MobileNet\n",
    "\n",
    "Pros: Known for being more efficient and achieving state-of-the-art performance with fewer parameters. It's designed to be computationally efficient and can scale well for different problems.\n",
    "Cons: Slightly more complex than VGG16, but it is still quite efficient.\n",
    "Best for: Faster training with fewer resources and high accuracy.\n",
    "\n",
    "- ResNet50:  #alternative ResNet34\n",
    "\n",
    "Pros: Very popular in transfer learning tasks. It’s very deep, yet its residual blocks allow for better learning of deep models. It has shown excellent performance on many tasks, including classification.\n",
    "Cons: Slightly more computationally intensive than VGG16, but generally faster than VGG16 in practice.\n",
    "Best for: Deep learning tasks requiring very good performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-3su_bPs4Ny"
   },
   "source": [
    "Let's Do Efficient Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pN5Ppm0psdjG"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkhDYrvAtTKU"
   },
   "source": [
    "Load the pre-trained EfficientNet model without the top layer (to replace it with your own classifier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZadno8ttL5-"
   },
   "outputs": [],
   "source": [
    "# Load the EfficientNetB0 model pre-trained on ImageNet, excluding the top classification layer\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build your own classifier on top\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(600, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Combine the base model and the new classifier\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQzFUn3-tdWi"
   },
   "source": [
    "Data Preprocessing with ImageDataGenerator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJT7qOdntdj-"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Load training and test data\n",
    "train = datagen.flow_from_directory(\n",
    "    directory='/content/drive/My Drive/Classroom/Topicos_Avanzados_IA/dataset_dogs_vs_cats/train',\n",
    "    target_size=(150, 150),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "test = datagen.flow_from_directory(\n",
    "    directory='/content/drive/My Drive/Classroom/Topicos_Avanzados_IA/dataset_dogs_vs_cats/test',\n",
    "    target_size=(150, 150),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVqccz_1t4V0"
   },
   "source": [
    "Train and Plot the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aU652u_Xt9AY"
   },
   "outputs": [],
   "source": [
    "# Train the model and capture the history\n",
    "history = model.fit(\n",
    "    train,\n",
    "    steps_per_epoch=train.samples // train.batch_size,\n",
    "    epochs=3,\n",
    "    validation_data=test,\n",
    "    validation_steps=test.samples // test.batch_size\n",
    ")\n",
    "\n",
    "# Plotting training & validation accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifNOZUtvuUHj"
   },
   "source": [
    "Switching Models:\n",
    "\n",
    "If you want to use ResNet50 or VGG16 instead, simply replace EfficientNetB0 with ResNet50 or VGG16, and ensure that you use the correct input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lw9HscWCuVgI"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3LXPqscCugsB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
